{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced Stochastic Model for PLL-TRNG\n",
    "\n",
    "This notebook implements an enhanced stochastic model for analyzing PLL-based True Random Number Generators (PLL-TRNG). The model considers:\n",
    "- PLL design parameters\n",
    "- Platform-specific characteristics\n",
    "- Excess phase noise modeling\n",
    "- Entropy analysis\n",
    "- Correlation studies\n",
    "\n",
    "This script uses Monte Carlo integration to solve the high-dimensional integration problem detailed in Sect. 4 of the paper. Monte Carlo integration is a numerical method, which uses random sampling to estimate integrals and works well for high-dimensional problems. Although Monte Carlo integration only provides approximate solutions, accuracy improves with more sample points. Three different sample sizes are recommended: \n",
    "- **$10^4$ (Low precision)**: fast computation time, suitable for quick estimates, larger error margin  \n",
    "- **$10^5$ (Medium precision)**: balanced speed and accuracy, good for most applications, moderate error reduction  \n",
    "- **$10^6$ (High precision)**: lower computation, best for final results, smallest error margin\n",
    "\n",
    "Note:\n",
    "To achieve the highest experimental accuracy, all data in the paper were obtained using high-precision Monte Carlo simulations with a size=$10^6$. The experimental results have been pre-saved in the `data` folder. High-precision simulations can be time-consuming. For quick verification, a lower precision can be used, though this may introduce significant errors especially in correlation analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "%pip install numpy matplotlib seaborn gmpy2 prettytable scipy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from numpy import pi\n",
    "from gmpy2 import invert\n",
    "from prettytable import PrettyTable\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "# Plot Parameters\n",
    "rc = {\n",
    "    'figure.figsize': (6, 4),\n",
    "    'figure.constrained_layout.use': True,\n",
    "    'savefig.format': 'pdf',\n",
    "    'font.size': 16,\n",
    "}\n",
    "mpl.rcParams.update(rc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLL-TRNG Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three PLL configurations for different performance:\n",
    "- **Config1 (Recommended)**\n",
    "  - Optimal correlation-sampling tradeoff\n",
    "  - *Used as primary configuration in the paper*\n",
    "- **Config2 (Speed Optimized)**\n",
    "  - Fastest speed\n",
    "  - Lower entropy\n",
    "- **Config3 (Resolution Optimized)**\n",
    "  - Highest coherent sampling resolution\n",
    "  - Stronger point correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config1: typical\n",
    "pll_config1 = {\n",
    "    \"M0\" : 43,\n",
    "    \"N0\" : 4,\n",
    "    \"C0\" : 7,\n",
    "    \"M1\" : 32,\n",
    "    \"N1\" : 3,\n",
    "    \"C1\" : 3\n",
    "}\n",
    "# Config2: best R\n",
    "pll_config2 = {\n",
    "    \"M0\" : 49,\n",
    "    \"N0\" : 4,\n",
    "    \"C0\" : 8,\n",
    "    \"M1\" : 16,\n",
    "    \"N1\" : 1,\n",
    "    \"C1\" : 3\n",
    "}\n",
    "# Config3: best S\n",
    "pll_config3 = {\n",
    "    \"M0\" : 53,\n",
    "    \"N0\" : 5,\n",
    "    \"C0\" : 7,\n",
    "    \"M1\" : 28,\n",
    "    \"N1\" : 3,\n",
    "    \"C1\" : 3\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default design parameters and platform parameters are the followings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLL-TRNG Design Parameters\n",
    "pll_fin = 1e8 # 100MHz\n",
    "pll_nr_output = 2 # number of outputs\n",
    "pll_phase_latency = 0.5 / pll_nr_output # latency between different outputs\n",
    "\n",
    "# PLL-TRNG Platform Parameter\n",
    "pll_BW = 1e6   # 1MHz\n",
    "pll_L0 = 1e-10 # -100dBc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions\n",
    "\n",
    "Here are some general-purpose utility functions used in the script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_invert(x, base):\n",
    "    return int(invert(x, base))\n",
    "\n",
    "def print_class_instance_vars(obj):\n",
    "    instance_vars = vars(obj)\n",
    "    table = PrettyTable(['Attribute', 'Value'])\n",
    "    for attr, value in instance_vars.items():\n",
    "        table.add_row([attr, value])\n",
    "    print(table)\n",
    "\n",
    "def display_class_members(instance):\n",
    "    table = PrettyTable()\n",
    "    members = instance.__dict__.keys()\n",
    "    values = instance.__dict__.values()\n",
    "    pretty_values = [\n",
    "        \"{:.4e}\".format(value) if isinstance(value, float) else value\n",
    "        for value in values\n",
    "    ]\n",
    "    table.field_names = members\n",
    "    table.add_row(pretty_values)\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Classes\n",
    "\n",
    "This section define the main classes used in the stochastic model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Class\n",
    "\n",
    "Classes for the design parameters and platform parameters for PLL-TRNGs as defined in Sect. 2.4 in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DesignParameter:\n",
    "    def __init__(self, fin, pll_config, nr_output, phase_latency):\n",
    "        # input frequency\n",
    "        self.fin = fin\n",
    "        # basic clk0 clk1 parameters\n",
    "        self.f0  = (pll_config['M0'] * self.fin) / (pll_config['C0'] * pll_config['N0'])\n",
    "        self.f1  = (pll_config['M1'] * self.fin) / (pll_config['C1'] * pll_config['N1'])\n",
    "        self.KM  = pll_config['M1'] * pll_config['N0'] * pll_config['C0']\n",
    "        self.KD  = pll_config['M0'] * pll_config['N1'] * pll_config['C1']\n",
    "        self.S   = self.KD # ui\n",
    "        self.R   = self.fin / (pll_config['N0'] * pll_config['N1'] * pll_config['C0'] * pll_config['C1'])\n",
    "        self.T0  = 1 / self.f0\n",
    "        self.T1  = 1 / self.f1\n",
    "        self.Tp  = self.KD / self.f0\n",
    "        self.delta = 1 / self.S\n",
    "        self.nr_output = nr_output\n",
    "        self.latency = phase_latency # ui\n",
    "\n",
    "class PlatformParameter:\n",
    "    def __init__(self, pll_duty, pll_initial_phase, L0, BW):\n",
    "        self.alpha = pll_duty           # duty cycle\n",
    "        self.phi_0 = pll_initial_phase  # initial phase\n",
    "        self.L0    = L0\n",
    "        self.BW    = BW\n",
    "        self.sigma_a = np.sqrt(self.L0 * self.BW / (4 * pi)) # ui\n",
    "        self.sigma_lt = np.sqrt(self.L0 * self.BW / (2 * pi)) # ui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excess Phase Class\n",
    "\n",
    "Class for the excess phase process for PLLs as defined in Sect. 3.3 in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExcessPhaseProcess:\n",
    "    def __init__(self, designParameter, platformParameter):\n",
    "        self.dp = designParameter\n",
    "        self.pp = platformParameter\n",
    "        self.dimension  = self.dp.KD * self.dp.nr_output\n",
    "    # scalar\n",
    "    def get_excess_phase_acf(self, ti, tj):\n",
    "        A = self.pp.L0 * pi * self.pp.BW\n",
    "        B = 2 * pi * self.pp.BW\n",
    "        return A * np.exp(-B * np.abs(ti - tj))\n",
    "    def get_excess_phase_var(self, ti):\n",
    "        return self.get_excess_phase_acf(ti, ti)\n",
    "    def get_excess_phase_corr(self, ti, tj):\n",
    "        return self.get_excess_phase_acf(ti, tj) / (np.sqrt(self.get_excess_phase_var(ti) * self.get_excess_phase_var(tj)))\n",
    "    # vector\n",
    "    def get_time_vec(self):\n",
    "        return np.array([self.dp.T0 * i - self.dp.latency * self.dp.T1 * j \n",
    "                        for i in range(self.dp.KD) \n",
    "                        for j in range(self.dp.nr_output)])\n",
    "    # matrix\n",
    "    def get_excess_noise_acf_matrix(self):\n",
    "        t = self.get_time_vec()\n",
    "        n = self.dimension\n",
    "        return np.array([[self.get_excess_phase_acf(t[i], t[j]) for i in range(n)] for j in range(n)])\n",
    "    def get_excess_noise_corr_matrix(self):\n",
    "        t = self.get_time_vec()\n",
    "        n = self.dimension\n",
    "        return np.array([[self.get_excess_phase_corr(t[i], t[j]) for i in range(n)] for j in range(n)])\n",
    "    # random variable\n",
    "    def get_random_variable_instance(self, size):\n",
    "        mean = np.zeros(self.dimension)\n",
    "        cov  = self.get_excess_noise_acf_matrix() / (2 * pi)**2\n",
    "        return np.random.multivariate_normal(mean, cov, int(size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy Model Class\n",
    "\n",
    "Class for the enhanced stochastic model for multiple-output PLL-TRNGs as described in Sect. 4.1 in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntropyModel(ExcessPhaseProcess):\n",
    "    def __init__(self, designParameter, platformParameter, size):\n",
    "        ExcessPhaseProcess.__init__(self,designParameter,platformParameter)\n",
    "        self.size = int(size)\n",
    "        self.samples = self.get_random_variable_instance(self.size)\n",
    "        self.contributors_arg_i = self.get_contributors_arg_i()\n",
    "        self.contributors_arg_j = self.get_contributors_arg_j()\n",
    "        self.contributors_cnt   = self.contributors_arg_i.size\n",
    "        self.pr_R = self.get_pr_R()\n",
    "    # Samples\n",
    "    def get_output_sample(self, k):\n",
    "        indices = np.arange(k, self.dimension, self.dp.nr_output)\n",
    "        return self.samples[:, indices]\n",
    "    # Reconstraction of sampled bits\n",
    "    def get_j(self, i):\n",
    "        return (i * self.dp.KM) % self.dp.KD\n",
    "    def get_i(self, j):\n",
    "        KM_invert = mod_invert(self.dp.KM, self.dp.KD)\n",
    "        return (j * KM_invert) % self.dp.KD\n",
    "    def get_phi_j(self, j, k):\n",
    "        return self.pp.phi_0 - k * self.dp.latency + j * self.dp.delta\n",
    "    def get_phi_i(self, i, k):\n",
    "        return self.get_phi_j(self.get_j(i), k)\n",
    "    def check_phi_i(self, excess_phase, i, k):\n",
    "        phi = excess_phase + self.get_phi_i(i, k)\n",
    "        return (0 < phi < self.pp.alpha) or (1 < phi < (1+self.pp.alpha)) or (-1 < phi < (-1 + self.pp.alpha)) or (2 < phi < (2+self.pp.alpha))\n",
    "    # Probability and Entropy\n",
    "    def get_pr_Xi(self, *args):\n",
    "        if len(args) == 1:\n",
    "            i, k = args[0] // self.dp.nr_output, args[0] % self.dp.nr_output\n",
    "        elif len(args == 2):\n",
    "            i, k = args\n",
    "        samples = self.get_output_sample(k)\n",
    "        phi_vec = samples[:, i]\n",
    "        check_vec = np.vectorize(lambda s: self.check_phi_i(phi_vec[s], i, k))(np.arange(self.size))\n",
    "        return check_vec.sum() / self.size\n",
    "    def get_pr_Xi_vec(self):\n",
    "        return np.array([self.get_pr_Xi(m) for m in range(self.dimension)])\n",
    "    def get_pr_Xm0Xm1(self, m0, m1):\n",
    "        cnt = 0\n",
    "        for s in range(self.size):\n",
    "            phi0 = self.samples[s, m0]\n",
    "            phi1 = self.samples[s, m1]\n",
    "            i0, k0 = m0 // self.dp.nr_output, m0 % self.dp.nr_output\n",
    "            i1, k1 = m1 // self.dp.nr_output, m1 % self.dp.nr_output\n",
    "            if self.check_phi_i(phi0, i0, k0) and self.check_phi_i(phi1, i1, k1):\n",
    "                cnt = cnt + 1\n",
    "        return cnt / self.size\n",
    "    def get_pr_R(self):\n",
    "        cnt = 0\n",
    "        for s in range(self.size):\n",
    "            r = False\n",
    "            for m in range(self.dimension):\n",
    "                phi = self.samples[s, m]\n",
    "                i = m // self.dp.nr_output\n",
    "                k = m % self.dp.nr_output\n",
    "                if self.check_phi_i(phi, i, k):\n",
    "                    r = not r\n",
    "            cnt = cnt + 1 if r else cnt\n",
    "        return cnt / self.size\n",
    "    def get_shannon_entropy(self):\n",
    "        p = self.pr_R\n",
    "        return -p * np.log2(p) - (1-p) * np.log2(1-p) if p != 0 else 0\n",
    "    def get_min_entropy(self):\n",
    "        p = self.pr_R\n",
    "        return -np.log2(np.maximum(p, 1-p)) if p != 0 else 0\n",
    "    def print_entropy(self):\n",
    "        shannon_entropy = self.get_shannon_entropy()\n",
    "        min_entropy = self.get_min_entropy()\n",
    "        print(f\"Bias: {self.pr_R-0.5}\")\n",
    "        table = PrettyTable()\n",
    "        table.field_names = [\"Entropy\", \"Value\"]\n",
    "        table.add_row([\"shannon\", shannon_entropy])\n",
    "        table.add_row([\"min\", min_entropy])\n",
    "        print(table)\n",
    "    # Contributors\n",
    "    def get_contributors_arg_m(self):\n",
    "        pr_Xj_vec = self.get_pr_Xi_vec()\n",
    "        condition = (pr_Xj_vec >= 0.0225) & (pr_Xj_vec <= 0.9775)\n",
    "        idxs = np.where(condition)[0]\n",
    "        return idxs\n",
    "    def get_contributors_arg_i(self):\n",
    "        pr_Xj_vec = self.get_pr_Xi_vec()\n",
    "        condition = (pr_Xj_vec >= 0.0225) & (pr_Xj_vec <= 0.9775)\n",
    "        idxs = np.where(condition)[0]\n",
    "        args_i = np.array([(m // self.dp.nr_output, m % self.dp.nr_output) for m in idxs])\n",
    "        return args_i\n",
    "    def get_contributors_arg_j(self):\n",
    "        args_j = np.array([(self.get_j(i), k) for i, k in self.contributors_arg_i])\n",
    "        return args_j\n",
    "    def print_contributors_args(self):\n",
    "        arg_zipped = np.array(list(zip(self.contributors_arg_i, self.contributors_arg_j)))\n",
    "        arg = np.array([(item[0][0], item[1][0], item[0][1]) for item in arg_zipped], dtype=int) # i, j, k\n",
    "        arg_sort = arg[np.lexsort((arg[:, 1], arg[:, 2]))]\n",
    "\n",
    "        table = PrettyTable()\n",
    "        table.field_names = [\"#\"] + [f\"{i+1}\" for i in range(len(arg_sort))]\n",
    "        i_row = [\"i\"] + [data[0] for data in arg_sort]\n",
    "        j_row = [\"j\"] + [data[1] for data in arg_sort]\n",
    "        k_row = [\"k\"] + [data[2] for data in arg_sort]\n",
    "        table.add_row(i_row)\n",
    "        table.add_row(j_row)\n",
    "        table.add_row(k_row)\n",
    "        print(table)\n",
    "    # Correlation of contributors\n",
    "    def get_bits_cov(self, m0, m1):\n",
    "        return self.get_pr_Xm0Xm1(m0, m1) - self.get_pr_Xi(m0) * self.get_pr_Xi(m1)\n",
    "    def get_bits_var(self, m):\n",
    "        p = self.get_pr_Xi(m)\n",
    "        return p*(1-p)\n",
    "    def get_bits_corr(self, m0, m1):\n",
    "        var0 = self.get_bits_var(m0)\n",
    "        var1 = self.get_bits_var(m1)\n",
    "        cov  = self.get_bits_cov(m0, m1)\n",
    "        return cov / np.sqrt(var0*var1)\n",
    "    def get_contributors_corr_matrix(self):\n",
    "        args = self.get_contributors_arg_m()\n",
    "        n    = args.size\n",
    "        return np.array([[self.get_bits_corr(args[i], args[j]) for j in range(n)] for i in range(n)])\n",
    "    def plt_contributors_corr_matrix(self):\n",
    "        m = self.get_contributors_corr_matrix()\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        sns.heatmap(m, square=True, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "        plt.show()\n",
    "    def plt_lag_corr(self):\n",
    "        arg_m = self.get_contributors_arg_m()\n",
    "        dimension = arg_m.size\n",
    "        corr_martix = self.get_contributors_corr_matrix()\n",
    "        t = self.get_time_vec()\n",
    "        data = np.array([(t[arg_m[i]]-t[arg_m[j]], corr_martix[i][j]) for i in range(dimension) for j in range(dimension)])\n",
    "        data_sort = sorted(data, key=lambda x: x[0])\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        x1, y1 = zip(*data_sort)\n",
    "        ax.plot(x1, y1, 'C0o:', label='bit')\n",
    "\n",
    "        x2 = np.linspace(-1.1 * max(x1), 1.1 * max(x1),1000)\n",
    "        y2 = np.exp(-2 * pi * self.pp.BW * np.abs(x2))\n",
    "        ax.plot(x2, y2, 'C2--', label='excess phase')\n",
    "\n",
    "        ax.legend()\n",
    "        ax.set_xlabel('lag')\n",
    "        ax.set_ylabel('correlation')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproduction of the paper figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyze the impact of PLL bandwidth on the correlation of the sampling points and reproduce the Fig. 7 in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_correlation_BW():\n",
    "    # Config3 w/ nr_output = 1\n",
    "    def get_data(BW):\n",
    "        designParameter = DesignParameter(\n",
    "            pll_fin,\n",
    "            pll_config3,\n",
    "            1,\n",
    "            0.5)\n",
    "        platformParameter = PlatformParameter(\n",
    "            (designParameter.KD - 1) / (2 * designParameter.KD), # alpha\n",
    "            designParameter.delta / 2, # phi_0\n",
    "            1e-10,\n",
    "            BW\n",
    "        )\n",
    "        excessPhase = ExcessPhaseProcess(\n",
    "            designParameter,\n",
    "            platformParameter\n",
    "        )\n",
    "        m = EntropyModel(\n",
    "            designParameter,\n",
    "            platformParameter,\n",
    "            size=1e6\n",
    "        )\n",
    "        arg_m = m.get_contributors_arg_m()\n",
    "        dimension = arg_m.size\n",
    "        corr_martix = m.get_contributors_corr_matrix()\n",
    "        t = m.get_time_vec()\n",
    "        data = np.array([(t[arg_m[i]]-t[arg_m[j]], corr_martix[i][j]) for i in range(dimension) for j       in range(dimension)])\n",
    "        data_sort = sorted(data, key=lambda x: x[0])\n",
    "        return data_sort\n",
    "\n",
    "    # Uncomment the following lines to generate data\n",
    "    # data_sort1 = get_data(0.5e6)\n",
    "    # data_sort2 = get_data(1e6)\n",
    "    # data_sort3 = get_data(5e6)\n",
    "    # x3, y3 = zip(*data_sort3)\n",
    "    # x2, y2 = zip(*data_sort2)\n",
    "    # x1, y1 = zip(*data_sort1)\n",
    "    # np.savetxt('./data/correlation_bandwidth/x1.txt', x1)\n",
    "    # np.savetxt('./data/correlation_bandwidth/x2.txt', x2)\n",
    "    # np.savetxt('./data/correlation_bandwidth/x3.txt', x3)\n",
    "    # np.savetxt('./data/correlation_bandwidth/y1.txt', y1)\n",
    "    # np.savetxt('./data/correlation_bandwidth/y2.txt', y2)\n",
    "    # np.savetxt('./data/correlation_bandwidth/y3.txt', y3)\n",
    "\n",
    "    # Load precomputed data\n",
    "    x1 = np.loadtxt('./data/correlation_bandwidth/x1.txt')\n",
    "    x2 = np.loadtxt('./data/correlation_bandwidth/x2.txt')\n",
    "    x3 = np.loadtxt('./data/correlation_bandwidth/x3.txt')\n",
    "    y1 = np.loadtxt('./data/correlation_bandwidth/y1.txt')\n",
    "    y2 = np.loadtxt('./data/correlation_bandwidth/y2.txt')\n",
    "    y3 = np.loadtxt('./data/correlation_bandwidth/y3.txt')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "    ax.plot(x3, y3, 'C2o:', label='BW=5.0MHz')\n",
    "    ax.plot(x2, y2, 'C1s:', label='BW=1.0MHz')\n",
    "    ax.plot(x1, y1, 'C0^:', label='BW=0.5MHz')\n",
    "\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.set_xlabel('lag[s]')\n",
    "    ax.set_ylabel('ACF')\n",
    "\n",
    "    axins = inset_axes(ax, width=\"40%\", height=\"60%\", loc=\"upper right\")\n",
    "    axins.plot(x3, y3, 'C2o:', label='BW=5.0MHz')\n",
    "    axins.plot(x2, y2, 'C1s:', label='BW=1.0MHz')\n",
    "    axins.plot(x1, y1, 'C0^:', label='BW=0.5MHz')\n",
    "    axins.set_xlim(0.2e-6, 1e-6)\n",
    "    axins.set_ylim(-0.1, 0.2)\n",
    "    \n",
    "    from matplotlib.ticker import MultipleLocator\n",
    "    axins.xaxis.set_major_locator(MultipleLocator(0.1))\n",
    "    axins.yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "    axins.set_xticks([])\n",
    "    axins.set_yticks([])\n",
    "\n",
    "    from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "    mark_inset(ax, axins, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plt_correlation_BW()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyze the impact of jitter indensity on the correlation of the sampling points and reproduce the Fig. 8 in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_correlation_L0():\n",
    "    # Config3 w/ nr_output = 1\n",
    "    def get_data(L0):\n",
    "        designParameter = DesignParameter(\n",
    "            pll_fin,\n",
    "            pll_config3,\n",
    "            1,\n",
    "            0.5)\n",
    "        platformParameter = PlatformParameter(\n",
    "            (designParameter.KD - 1) / (2 * designParameter.KD), # alpha\n",
    "            designParameter.delta / 2, # phi_0\n",
    "            L0,\n",
    "            1e6\n",
    "        )\n",
    "        excessPhase = ExcessPhaseProcess(\n",
    "            designParameter,\n",
    "            platformParameter\n",
    "        )\n",
    "        m = EntropyModel(\n",
    "            designParameter,\n",
    "            platformParameter,\n",
    "            size=1e6\n",
    "        )\n",
    "        arg_m = m.get_contributors_arg_m()\n",
    "        dimension = arg_m.size\n",
    "        corr_martix = m.get_contributors_corr_matrix()\n",
    "        t = m.get_time_vec()\n",
    "        data = np.array([(t[arg_m[i]]-t[arg_m[j]], corr_martix[i][j]) for i in range(dimension) for j in range(dimension)])\n",
    "        data_sort = sorted(data, key=lambda x: x[0])\n",
    "        return data_sort\n",
    "\n",
    "    # Uncomment the following lines to generate data\n",
    "    # data_sort1 = get_data(1e-10) # -100dBc\n",
    "    # data_sort2 = get_data(10e-10) # -90dBc\n",
    "    # x1, y1 = zip(*data_sort1)\n",
    "    # x2, y2 = zip(*data_sort2)\n",
    "    # np.savetxt('./data/correlation_L0/x1.txt', x1)\n",
    "    # np.savetxt('./data/correlation_L0/x2.txt', x2)\n",
    "    # np.savetxt('./data/correlation_L0/y1.txt', y1)\n",
    "    # np.savetxt('./data/correlation_L0/y2.txt', y2)\n",
    "\n",
    "    # Load the precomputed\n",
    "    x1 = np.loadtxt('./data/correlation_L0/x1.txt')\n",
    "    x2 = np.loadtxt('./data/correlation_L0/x2.txt')\n",
    "    y1 = np.loadtxt('./data/correlation_L0/y1.txt')\n",
    "    y2 = np.loadtxt('./data/correlation_L0/y2.txt')\n",
    "\n",
    "    x3 = np.linspace(-1.1 * max(x1), 1.1 * max(x1),1000)\n",
    "    y3 = np.exp(-2 * pi * 1e6 * np.abs(x3))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    ax.plot(x3, y3, color=(0.5, 0.7, 0.5), label='excess phase', lw=3)\n",
    "    ax.plot(x3, -y3, color=(0.5, 0.7, 0.5), lw=3)\n",
    "\n",
    "    ax.plot(x2, y2, 'C0o:', label='bit, L0=-90dBc/Hz')\n",
    "    ax.plot(x1, y1, 'C1^:', label='bit, L0=-100dBc/Hz')\n",
    "    ax.fill_between(x3, y3, -y3, color=(0.8, 0.95, 0.8), alpha=0.5)\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.set_xlabel('lag[s]')\n",
    "    ax.set_ylabel('ACF')\n",
    "    ax.set_ylim(-0.5,1)\n",
    "\n",
    "    axins = inset_axes(ax, width=\"40%\", height=\"60%\", loc=\"upper right\")\n",
    "    axins.plot(x3, y3, color=(0.5, 0.7, 0.5), label='excess phase', lw=3)\n",
    "    axins.plot(x3, -y3, color=(0.5, 0.7, 0.5), label='excess phase', lw=3)\n",
    "    axins.plot(x2, y2, 'C0o:', label='bit, L0=-100dBc')\n",
    "    axins.plot(x1, y1, 'C1^:', label='bit, L0=-90dBc')\n",
    "    axins.set_xlim(0.35e-6, 1.2e-6)\n",
    "    axins.set_ylim(-0.1, 0.2)\n",
    "    axins.fill_between(x3, y3, -y3, color=(0.8, 0.95, 0.8), alpha=0.5)\n",
    "\n",
    "    from matplotlib.ticker import MultipleLocator\n",
    "    axins.xaxis.set_major_locator(MultipleLocator(0.1))\n",
    "    axins.yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "    axins.set_xticks([])\n",
    "    axins.set_yticks([])\n",
    "\n",
    "    from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "    mark_inset(ax, axins, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plt_correlation_L0()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyze the impact of PLL bandwidth on entropy and reproduce the Fig. 9 in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_entropy_BW():\n",
    "    data = np.genfromtxt('./data/entropy_BW/entropy_BW.txt', skip_header=2)\n",
    "    BW = data[:,0] / 1e6\n",
    "    H1 = data[:,1]\n",
    "    Hmin = data[:,2]\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(BW, H1, 'C0o:', label=r'$H_1$')\n",
    "    ax.plot(BW, Hmin, 'C1^:', label=r'$H_{\\infty}$')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Bandwidth[MHz]')\n",
    "    ax.set_ylabel('Entropy')\n",
    "    plt.show()\n",
    "\n",
    "plt_entropy_BW()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Show the correlation matrix of the sampling points for different outputs and reproduce the Fig. 10 in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_correlation_matrix():\n",
    "    def get_data(nr_output):\n",
    "        designParameter = DesignParameter(\n",
    "            pll_fin,\n",
    "            pll_config2,\n",
    "            nr_output,\n",
    "            0.5 / nr_output)\n",
    "        platformParameter = PlatformParameter(\n",
    "            (designParameter.KD - 1) / (2 * designParameter.KD), # alpha\n",
    "            designParameter.delta / 2, # phi_0\n",
    "            1e-10,\n",
    "            1e6\n",
    "        )\n",
    "        excessPhase = ExcessPhaseProcess(\n",
    "            designParameter,\n",
    "            platformParameter\n",
    "        )\n",
    "        m = EntropyModel(\n",
    "            designParameter,\n",
    "            platformParameter,\n",
    "            size=1e6\n",
    "        )\n",
    "        return m\n",
    "\n",
    "    # Uncomment the following lines to generate data and save the correlation matrix\n",
    "    # for pll_nr_output in [1, 2]:\n",
    "    #     m = get_data(pll_nr_output)\n",
    "    #     matrix = m.get_contributors_corr_matrix()\n",
    "    #     np.savetxt('./data/correlation_matrix/correlation_matrix'+str(pll_nr_output)+'.txt', matrix)\n",
    "    \n",
    "    # Load the precomputed correlation matrix from file (Config2)\n",
    "    for pll_nr_output in [1, 2]:\n",
    "        matrix = np.loadtxt('./data/correlation_matrix/correlation_matrix'+str(pll_nr_output)+'.txt')\n",
    "        cmap = 'Blues'\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        sns.heatmap(matrix, \n",
    "                    square=True, \n",
    "                    annot=True, \n",
    "                    cmap=cmap, \n",
    "                    fmt=\".2f\", \n",
    "                    annot_kws={\"size\": 16},\n",
    "                    linewidths=0.5)\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "plt_correlation_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyze the impact of the number of PLL outputs on the correlation of the sampling points and reproduce the Fig. 11 in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_correlation_output():\n",
    "    def get_data(nr_output):\n",
    "        # Config2\n",
    "        designParameter = DesignParameter(\n",
    "            pll_fin,\n",
    "            pll_config2,\n",
    "            nr_output, # {1, 2}\n",
    "            0.5 / nr_output)\n",
    "        platformParameter = PlatformParameter(\n",
    "            (designParameter.KD - 1) / (2 * designParameter.KD), # alpha\n",
    "            designParameter.delta / 2, # phi_0\n",
    "            1e-10,\n",
    "            1e6\n",
    "        )\n",
    "        excessPhase = ExcessPhaseProcess(\n",
    "            designParameter,\n",
    "            platformParameter\n",
    "        )\n",
    "        m = EntropyModel(\n",
    "            designParameter,\n",
    "            platformParameter,\n",
    "            size=1e6\n",
    "        )\n",
    "        return m\n",
    "\n",
    "    # Uncomment the following lines to generate data\n",
    "    # for pll_nr_output in [1, 2]:\n",
    "    #     m = get_data(pll_nr_output)\n",
    "    #     shannon_entropy = m.get_shannon_entropy()\n",
    "    #     min_entropy = m.get_min_entropy()\n",
    "    #     arg_m = m.get_contributors_arg_m()\n",
    "    #     dimension = arg_m.size\n",
    "    #     corr_martix = m.get_contributors_corr_matrix()\n",
    "    #     t = m.get_time_vec()\n",
    "    #     data = np.array([(t[arg_m[i]]-t[arg_m[j]], corr_martix[i][j]) for i in range(dimension) for j in range(dimension)])\n",
    "    #     data_sort = sorted(data, key=lambda x: x[0])\n",
    "    #     np.savetxt(f'./data/correlation_output/data_sort_{pll_nr_output}.txt', data_sort)\n",
    "    #     np.savetxt(f'./data/correlation_output/shannon_entropy_{pll_nr_output}.txt', [shannon_entropy])\n",
    "    #     np.savetxt(f'./data/correlation_output/min_entropy_{pll_nr_output}.txt', [min_entropy])\n",
    "\n",
    "    # Load the precomputed data\n",
    "    for pll_nr_output in [1, 2]:\n",
    "        data_sort = np.loadtxt(f'./data/correlation_output/data_sort_{pll_nr_output}.txt')\n",
    "        shannon_entropy = np.loadtxt(f'./data/correlation_output/shannon_entropy_{pll_nr_output}.txt')\n",
    "        min_entropy = np.loadtxt(f'./data/correlation_output/min_entropy_{pll_nr_output}.txt')\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        x1, y1 = zip(*data_sort)\n",
    "        ax.plot(x1, y1, 'C0o:', label='bit')\n",
    "        \n",
    "        x2 = np.linspace(-1.1 * max(x1), 1.1 * max(x1),1000)\n",
    "        y2 = np.exp(-2 * pi * 1e6 * np.abs(x2))\n",
    "        ax.plot(x2, y2, 'C2--', label='excess phase')\n",
    "\n",
    "        ax.text(4e-7, 0.6, f'$H_1 = {shannon_entropy:.4f}$')\n",
    "        ax.text(4e-7, 0.4, f'$H_{{\\\\infty}} = {min_entropy:.4f}$')\n",
    "        ax.legend()\n",
    "        ax.set_xlabel('lag[s]')\n",
    "        ax.set_ylabel('ACF')\n",
    "        plt.show()\n",
    "\n",
    "plt_correlation_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case study\n",
    "\n",
    "Build simulation model and show basic parameters for `pll_confg1` with the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model parameters\n",
    "designParameter = DesignParameter(\n",
    "    pll_fin,\n",
    "    pll_config1,\n",
    "    pll_nr_output,\n",
    "    pll_phase_latency)\n",
    "\n",
    "platformParameter = PlatformParameter(\n",
    "    (designParameter.KD - 1) / (2 * designParameter.KD),\n",
    "    designParameter.delta / 2,\n",
    "    pll_L0,\n",
    "    pll_BW\n",
    ")\n",
    "\n",
    "m = EntropyModel(\n",
    "    designParameter,\n",
    "    platformParameter,\n",
    "    size=1e4 # for quick test, use 1e6 for real test\n",
    ")\n",
    "\n",
    "# Display parameters\n",
    "print(\"Design Parameter:\")\n",
    "display_class_members(designParameter)\n",
    "print(\"\\nPlatform Parameter:\")\n",
    "display_class_members(platformParameter)\n",
    "print(\"\\nContributors args:\")\n",
    "m.print_contributors_args()\n",
    "print(\"\\nEntropy Study:\")\n",
    "m.print_entropy()\n",
    "\n",
    "# Generate plots\n",
    "print(\"Plotting correlation matrix...\")\n",
    "m.plt_contributors_corr_matrix()\n",
    "\n",
    "print(\"Plotting lag correlation...\")\n",
    "m.plt_lag_corr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
